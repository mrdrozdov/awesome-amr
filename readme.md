# Awesome AMR [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

> A curated list of awesome frameworks, tools, and repos for AMR parsing.


## Utilities

- [penman](https://github.com/goodmami/penman) - The Penman package is a library for working with graphs in the PENMAN format. Its primary job is thus parsing the serialized form into an internal graph representation and format graphs into the serialized form again. Once parsed, the graphs can be inspected and manipulated, depending on one's needs.
- [amr-utils](https://github.com/ablodge/amr-utils) - AMR-utils is a python package for working with AMR data, with tools for reading AMRs and alignments, performing graph operations, and displaying and visualizing AMR data.
- [AMRICA](https://github.com/nsaphra/AMRICA) - Visualize AMRs with inter-annotator disagreement and bitext alignment.
- [amrlib](https://github.com/bjascob/amrlib) - A python library that makes AMR parsing, generation and visualization simple.
- [amr-ld](https://github.com/BMKEG/amr-ld) - A Python library for mapping AMRs to linked data formats (such as RDF and JSON-LD).
- [amr_library](https://github.com/shibhansh/amr_library) - Textual representation of AMR(Abstract Meaning Representation) can be very hard to process because of it's complex structure. This reprository provides code to simplify the process of using AMR and is aimed at increasing accessibility of AMR.


## Papers and Models

- [Transition-based AMR Parser](https://github.com/IBM/transition-amr-parser) - Neural transition-based parser for Abstract Meaning Representation (AMR) producing state-of-the-art AMR parsing and reliable token to node alignments. References: [Fernandez Astudillo et al 2020](https://www.aclweb.org/anthology/2020.findings-emnlp.89), [Zhou et al 2021a](https://www.aclweb.org/anthology/2021.naacl-main.443), [Zhou et al 2021b](https://openreview.net/forum?id=qjDQCHLXCNj), [Drozdov et al 2022](https://arxiv.org/abs/2205.01464)
- [SPRING](https://github.com/SapienzaNLP/spring) - This is the repo for SPRING (Symmetric ParsIng aNd Generation), a novel approach to semantic parsing and generation, presented at AAAI 2021. References: [Bevilacqua et al 2021](https://ojs.aaai.org/index.php/AAAI/article/view/17489)
- [AMR-gs](https://github.com/jcyk/AMR-gs) - Code for the ACL2020 paper, AMR Parsing via Graph-Sequence Iterative Inference. References: [Cai and Lam 2020](http://arxiv.org/abs/2004.05572)
- [Unified Transition-Parser](https://github.com/DreamerDeo/HIT-SCIR-CoNLL2019) - This repository accompanies the paper, "HIT-SCIR at MRP 2019: A Unified Pipeline for Meaning Representation Parsing via Efficient Training and Effective Encoding", providing codes to train models and pre/post-precessing mrp dataset. References: [Che et al 2019](https://aclanthology.org/K19-2007.pdf)
- [RikVN/AMR](https://github.com/RikVN/AMR) - This repository contains a list of scripts that help in pre- and post-processing for neural AMR parsing. It helps put the AMR files into structures sequence-to-sequence models can handle. References: [Noord & Bos 2017](https://clinjournal.org/clinj/article/view/72/64), [Noord & Bos 2017](http://aclweb.org/anthology/W/W17/W17-7306.pdf)
- [Unsupervised-SAS](https://github.com/vgupta123/Unsupervised-SAS) - This repo contains the source code of acl-srw 2020 work on the AMR (Abstract Meaning Representation) based approach for abstractive summarization i.e. source code of Unsupervised Semantic Abstractive Summarization paper. References: [Dohare et al 2018](https://www.aclweb.org/anthology/P18-3011)
- [Neural AMR](https://github.com/sinantie/NeuralAmr) - Torch implementation of sequence-to-sequence models for AMR parsing and generation based on the Harvard NLP framework. References: [Konstas et al 2017](https://arxiv.org/abs/1704.08381)
- [Better Transition-Based AMR Parsing with a Refined Search Space](https://github.com/Cartus/AMR-Parser) - DyNet implementation of the transition-based AMR parser. Provides the code for aligner and the parser. References: [Guo and Lu 2018](http://www.statnlp.org/research/sp/zhijiang18emnlp.pdf)

## Contribute

Contributions welcome! Read the [contribution guidelines](contributing.md) first.
